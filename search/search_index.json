{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Sejam bem-vindos Introdu\u00e7\u00e3o Manterei nesse reposit\u00f3rio uma s\u00e9rie de documenta\u00e7\u00f5es e dicas sobre sistemas ou projetos que estudo e/ou pesquiso. Com isto, tenho os seguintes objetivos em mente: Manter documentado o que fiz, fa\u00e7o e farei para facilitar minha vida; Aprender a usar melhor o Mkdocs; Ajudar outras pessoas que estejam pesquisando coisas parecidas. \u00c9 bom notar que muitas das coisas documentadas aqui podem n\u00e3o estar otimizadas ou mesmo terem sido feitas da maneira correta, pois em sua maioria s\u00e3o meus testes e projetos pessoais. Usem por sua conta e risco! Como fiz esta p\u00e1gina? Esta p\u00e1gina usa como base o Mkdocs , que cria sites est\u00e1ticos com base em arquivos Markdown (README.md lembra?). Escolhi o tema Material por ser o tema usado por padr\u00e3o pelo Backstage , que \u00e9 um projeto que acompanho.","title":"Home"},{"location":"#sejam-bem-vindos","text":"","title":"Sejam bem-vindos"},{"location":"#introducao","text":"Manterei nesse reposit\u00f3rio uma s\u00e9rie de documenta\u00e7\u00f5es e dicas sobre sistemas ou projetos que estudo e/ou pesquiso. Com isto, tenho os seguintes objetivos em mente: Manter documentado o que fiz, fa\u00e7o e farei para facilitar minha vida; Aprender a usar melhor o Mkdocs; Ajudar outras pessoas que estejam pesquisando coisas parecidas. \u00c9 bom notar que muitas das coisas documentadas aqui podem n\u00e3o estar otimizadas ou mesmo terem sido feitas da maneira correta, pois em sua maioria s\u00e3o meus testes e projetos pessoais. Usem por sua conta e risco!","title":"Introdu\u00e7\u00e3o"},{"location":"#como-fiz-esta-pagina","text":"Esta p\u00e1gina usa como base o Mkdocs , que cria sites est\u00e1ticos com base em arquivos Markdown (README.md lembra?). Escolhi o tema Material por ser o tema usado por padr\u00e3o pelo Backstage , que \u00e9 um projeto que acompanho.","title":"Como fiz esta p\u00e1gina?"},{"location":"dicas/","text":"Dicas para o uso do Mkdocs Code Sampling const serviceEntityPage = ( < EntityLayout > < EntityLayout . Route path = \"/\" title = \"Overview\" > < Grid container spacing = { 3 } alignItems = \"stretch\" > < Grid item md = { 6 } > < EntityAboutCard variant = \"gridItem\" /> < /Grid> < /Grid> < /EntityLayout.Route> < EntityLayout . Route path = \"/docs\" title = \"Docs\" > < EntityTechdocsContent /> < /EntityLayout.Route> < /EntityLayout> ); def getUsersInGroup ( targetGroup , secure = False ): if __debug__ : print ( 'targetGroup=[' + targetGroup + ']' )","title":"Dicas para o uso do Mkdocs"},{"location":"dicas/#dicas-para-o-uso-do-mkdocs","text":"","title":"Dicas para o uso do Mkdocs"},{"location":"dicas/#code-sampling","text":"const serviceEntityPage = ( < EntityLayout > < EntityLayout . Route path = \"/\" title = \"Overview\" > < Grid container spacing = { 3 } alignItems = \"stretch\" > < Grid item md = { 6 } > < EntityAboutCard variant = \"gridItem\" /> < /Grid> < /Grid> < /EntityLayout.Route> < EntityLayout . Route path = \"/docs\" title = \"Docs\" > < EntityTechdocsContent /> < /EntityLayout.Route> < /EntityLayout> ); def getUsersInGroup ( targetGroup , secure = False ): if __debug__ : print ( 'targetGroup=[' + targetGroup + ']' )","title":"Code Sampling"},{"location":"aplicacoes/jitsi/","text":"Jitsi Meet Githubs https://github.com/jitsi/jitsi-meet https://github.com/jitsi/docker-jitsi-meet Como iniciar? # Clonar o ambiente, nesse caso usaremos o oficial. git clone https://github.com/jitsi/docker-jitsi-meet.git cd docker-jitsi-meet # Criaremos o arquivo de variaveis de ambiente. mv env.example .env chmod +x gen-passwords.sh # Gerar as variaveis de seguran\u00e7a. ./gen-passwords.sh Ap\u00f3s isto, edite as variaveis necessarias no arquivo .env. As mais importantes s\u00e3o: # Local onde os arquivos de configura\u00e7\u00e3o ser\u00e3o salvos (incluindo certificados) CONFIG=./jitsi-meet-cfg # Portas do frontend HTTP_PORT=80 HTTPS_PORT=8443 # URL que ser\u00e1 usada para acessar o Meet, \u00e9 obrigat\u00f3ria! PUBLIC_URL=http://jitsi.localhost # IP do host Docker DOCKER_HOST_ADDRESS=10.0.0.1 \u00c9 importante notar que os endere\u00e7os marcados como .meet.jitsi s\u00e3o de uso interno e podem/devem ser mantidos como est\u00e3o. Para iniciar usando Docker-compose: docker-compose up -d Etherpad O Etherpad \u00e9 um gestor de arquivos compartilhados para uso em grupo que pode ser utilizado dentro de uma reuni\u00e3o do meet. Para utiliz\u00e1 lo, adicione o seguinte servi\u00e7o no docker-compose.yml: etherpad: image: etherpad/etherpad:1.8.6 restart: ${RESTART_POLICY} environment: - TITLE=${ETHERPAD_TITLE} - DEFAULT_PAD_TEXT=${ETHERPAD_DEFAULT_PAD_TEXT} - SKIN_NAME=${ETHERPAD_SKIN_NAME} - SKIN_VARIANTS=${ETHERPAD_SKIN_VARIANTS} - SUPPRESS_ERRORS_IN_PAD_TEXT networks: meet.jitsi: aliases: - etherpad.meet.jitsi E adicione as seguintes vari\u00e1veis de ambiente no arquivo .env. # # Etherpad integration (for document sharing) # # Set etherpad-lite URL in docker local network (uncomment to enable) ETHERPAD_URL_BASE=http://etherpad.meet.jitsi:9001 # Set etherpad-lite public URL (uncomment to enable) ETHERPAD_PUBLIC_URL=http://jitsi.localhost/etherpad/p/ # Name your etherpad instance! ETHERPAD_TITLE=Video Chat # The default text of a pad ETHERPAD_DEFAULT_PAD_TEXT=Welcome to Web Chat!\\n\\n # Name of the skin for etherpad ETHERPAD_SKIN_NAME=colibris # Skin variants for etherpad ETHERPAD_SKIN_VARIANTS=super-light-toolbar super-light-editor light-background full-width-editor # To remove a warning in pad texts SUPPRESS_ERRORS_IN_PAD_TEXT=true \u00c9 importante notar que o ETHERPAD_URL_BASE refere-se ao endere\u00e7o interno do Etherpad, o Nginx do frontend criar\u00e1 uma rota apontando o endere\u00e7o de /etherpad para a URL interna. Da mesma forma \u00e9 importante manter a ETHERPAD_PUBLIC_URL com o mesmo host do seu ambiente, para evitar erros de CORS. Autentica\u00e7\u00e3o \u00c9 poss\u00edvel usar o meet com autentica\u00e7\u00e3o, incluindo em modo h\u00edbrido com usu\u00e1rios autenticados e n\u00e3o autenticados, segue algumas coisas interessantes: Quando definimos a autentica\u00e7\u00e3o, apenas usu\u00e1rios logados podem criar salas. Caso definamos ENABLE_GUESTS como true, usu\u00e1rios deslogados poder\u00e3o entrar em salas j\u00e1 criadas. Usu\u00e1rios deslogados t\u00eam o terr\u00edvel h\u00e1bito de n\u00e3o colocarem um nome no seu perfil. As op\u00e7\u00f5es ENABLE_WELCOME_PAGE, ENABLE_PREJOIN_PAGE, ENABLE_CLOSE_PAGE e ENABLE_REQUIRE_DISPLAY_NAME cuidam muito bem disso. LDAP Est\u00e1 \u00e9 uma configura\u00e7\u00e3o padr\u00e3o de autentica\u00e7\u00e3o por LDAP para um servidor de Active Directory com Windows. ENABLE_AUTH=1 ENABLE_GUESTS=1 AUTH_TYPE=ldap LDAP_URL=ldap://adserver:389 LDAP_BASE=OU=users,DC=contoso,DC=com LDAP_BINDDN=CN=user,OU=users,DC=contoso,DC=com LDAP_BINDPW=password LDAP_FILTER=(samaccountname=%u) LDAP_AUTH_METHOD=bind LDAP_USE_TLS=0 Keycloak Vamos tentar usar o Keycloak como metodo de autentica\u00e7\u00e3o. M\u00e9tricas Podemos verificar as metricas de uso do JVB adicionando os seguintes endpoints na variavel JVB_ENABLE_APIS: JVB_ENABLE_APIS=rest,colibri,stats Ap\u00f3s isto, podemos acessar o container do JVB na porta 8080 (http://jvb:8080/colibri/stats); \u00e9 importante notar que ele gera as metricas em formato Json, isso pode ser util em alguns casos, por\u00e9m em geral gostariamos que ele nos entregasse algo no formato do Prometheus. Para isso podemos usar um workaround interessante: Prometheus Podemos usar um container utilitario para traduzir as metricas: exporter: image: systemli/prometheus-jitsi-meet-exporter:latest restart: ${RESTART_POLICY} command: -videobridge-url http://jvb:8080/colibri/stats ports: - 9888:9888 networks: meet.jitsi:","title":"Jitsi"},{"location":"aplicacoes/jitsi/#jitsi-meet","text":"","title":"Jitsi Meet"},{"location":"aplicacoes/jitsi/#githubs","text":"https://github.com/jitsi/jitsi-meet https://github.com/jitsi/docker-jitsi-meet","title":"Githubs"},{"location":"aplicacoes/jitsi/#como-iniciar","text":"# Clonar o ambiente, nesse caso usaremos o oficial. git clone https://github.com/jitsi/docker-jitsi-meet.git cd docker-jitsi-meet # Criaremos o arquivo de variaveis de ambiente. mv env.example .env chmod +x gen-passwords.sh # Gerar as variaveis de seguran\u00e7a. ./gen-passwords.sh Ap\u00f3s isto, edite as variaveis necessarias no arquivo .env. As mais importantes s\u00e3o: # Local onde os arquivos de configura\u00e7\u00e3o ser\u00e3o salvos (incluindo certificados) CONFIG=./jitsi-meet-cfg # Portas do frontend HTTP_PORT=80 HTTPS_PORT=8443 # URL que ser\u00e1 usada para acessar o Meet, \u00e9 obrigat\u00f3ria! PUBLIC_URL=http://jitsi.localhost # IP do host Docker DOCKER_HOST_ADDRESS=10.0.0.1 \u00c9 importante notar que os endere\u00e7os marcados como .meet.jitsi s\u00e3o de uso interno e podem/devem ser mantidos como est\u00e3o. Para iniciar usando Docker-compose: docker-compose up -d","title":"Como iniciar?"},{"location":"aplicacoes/jitsi/#etherpad","text":"O Etherpad \u00e9 um gestor de arquivos compartilhados para uso em grupo que pode ser utilizado dentro de uma reuni\u00e3o do meet. Para utiliz\u00e1 lo, adicione o seguinte servi\u00e7o no docker-compose.yml: etherpad: image: etherpad/etherpad:1.8.6 restart: ${RESTART_POLICY} environment: - TITLE=${ETHERPAD_TITLE} - DEFAULT_PAD_TEXT=${ETHERPAD_DEFAULT_PAD_TEXT} - SKIN_NAME=${ETHERPAD_SKIN_NAME} - SKIN_VARIANTS=${ETHERPAD_SKIN_VARIANTS} - SUPPRESS_ERRORS_IN_PAD_TEXT networks: meet.jitsi: aliases: - etherpad.meet.jitsi E adicione as seguintes vari\u00e1veis de ambiente no arquivo .env. # # Etherpad integration (for document sharing) # # Set etherpad-lite URL in docker local network (uncomment to enable) ETHERPAD_URL_BASE=http://etherpad.meet.jitsi:9001 # Set etherpad-lite public URL (uncomment to enable) ETHERPAD_PUBLIC_URL=http://jitsi.localhost/etherpad/p/ # Name your etherpad instance! ETHERPAD_TITLE=Video Chat # The default text of a pad ETHERPAD_DEFAULT_PAD_TEXT=Welcome to Web Chat!\\n\\n # Name of the skin for etherpad ETHERPAD_SKIN_NAME=colibris # Skin variants for etherpad ETHERPAD_SKIN_VARIANTS=super-light-toolbar super-light-editor light-background full-width-editor # To remove a warning in pad texts SUPPRESS_ERRORS_IN_PAD_TEXT=true \u00c9 importante notar que o ETHERPAD_URL_BASE refere-se ao endere\u00e7o interno do Etherpad, o Nginx do frontend criar\u00e1 uma rota apontando o endere\u00e7o de /etherpad para a URL interna. Da mesma forma \u00e9 importante manter a ETHERPAD_PUBLIC_URL com o mesmo host do seu ambiente, para evitar erros de CORS.","title":"Etherpad"},{"location":"aplicacoes/jitsi/#autenticacao","text":"\u00c9 poss\u00edvel usar o meet com autentica\u00e7\u00e3o, incluindo em modo h\u00edbrido com usu\u00e1rios autenticados e n\u00e3o autenticados, segue algumas coisas interessantes: Quando definimos a autentica\u00e7\u00e3o, apenas usu\u00e1rios logados podem criar salas. Caso definamos ENABLE_GUESTS como true, usu\u00e1rios deslogados poder\u00e3o entrar em salas j\u00e1 criadas. Usu\u00e1rios deslogados t\u00eam o terr\u00edvel h\u00e1bito de n\u00e3o colocarem um nome no seu perfil. As op\u00e7\u00f5es ENABLE_WELCOME_PAGE, ENABLE_PREJOIN_PAGE, ENABLE_CLOSE_PAGE e ENABLE_REQUIRE_DISPLAY_NAME cuidam muito bem disso.","title":"Autentica\u00e7\u00e3o"},{"location":"aplicacoes/jitsi/#ldap","text":"Est\u00e1 \u00e9 uma configura\u00e7\u00e3o padr\u00e3o de autentica\u00e7\u00e3o por LDAP para um servidor de Active Directory com Windows. ENABLE_AUTH=1 ENABLE_GUESTS=1 AUTH_TYPE=ldap LDAP_URL=ldap://adserver:389 LDAP_BASE=OU=users,DC=contoso,DC=com LDAP_BINDDN=CN=user,OU=users,DC=contoso,DC=com LDAP_BINDPW=password LDAP_FILTER=(samaccountname=%u) LDAP_AUTH_METHOD=bind LDAP_USE_TLS=0","title":"LDAP"},{"location":"aplicacoes/jitsi/#keycloak","text":"Vamos tentar usar o Keycloak como metodo de autentica\u00e7\u00e3o.","title":"Keycloak"},{"location":"aplicacoes/jitsi/#metricas","text":"Podemos verificar as metricas de uso do JVB adicionando os seguintes endpoints na variavel JVB_ENABLE_APIS: JVB_ENABLE_APIS=rest,colibri,stats Ap\u00f3s isto, podemos acessar o container do JVB na porta 8080 (http://jvb:8080/colibri/stats); \u00e9 importante notar que ele gera as metricas em formato Json, isso pode ser util em alguns casos, por\u00e9m em geral gostariamos que ele nos entregasse algo no formato do Prometheus. Para isso podemos usar um workaround interessante:","title":"M\u00e9tricas"},{"location":"aplicacoes/jitsi/#prometheus","text":"Podemos usar um container utilitario para traduzir as metricas: exporter: image: systemli/prometheus-jitsi-meet-exporter:latest restart: ${RESTART_POLICY} command: -videobridge-url http://jvb:8080/colibri/stats ports: - 9888:9888 networks: meet.jitsi:","title":"Prometheus"},{"location":"aplicacoes/keycloak/","text":"Keycloak Githubs https://github.com/Jarzamendia/keycloak.git Docker-compose Exporta\u00e7\u00e3o de realm","title":"Keycloak"},{"location":"aplicacoes/keycloak/#keycloak","text":"","title":"Keycloak"},{"location":"aplicacoes/keycloak/#githubs","text":"https://github.com/Jarzamendia/keycloak.git","title":"Githubs"},{"location":"aplicacoes/keycloak/#docker-compose","text":"","title":"Docker-compose"},{"location":"aplicacoes/keycloak/#exportacao-de-realm","text":"","title":"Exporta\u00e7\u00e3o de realm"},{"location":"aplicacoes/mattermost/","text":"Mattermost Script de limpeza A vers\u00e3o free do mattermost (Team Edition) n\u00e3o d\u00e1 suporte a limpeza automatizada das mensagens\\m\u00eddias. Para resolver isto, o repo https://github.com/aljazceru/mattermost-retention criou um script de limpeza dos anexos e mensagens antigas. Basicamente voc\u00ea configura os dados do banco e a pasta 'data' do MM, tudo anterior ao per\u00edodo de reten\u00e7\u00e3o definido ser\u00e1 apagado. O processo demora um pouco mas resolve bem o problema de ac\u00famulo de mensagens e anexos. Recentemente eu fiz uma PR adicionando suporte ao Mysql, pois a vers\u00e3o da epoca s\u00f3 aceitava Postgres.","title":"Mattermost"},{"location":"aplicacoes/mattermost/#mattermost","text":"","title":"Mattermost"},{"location":"aplicacoes/mattermost/#script-de-limpeza","text":"A vers\u00e3o free do mattermost (Team Edition) n\u00e3o d\u00e1 suporte a limpeza automatizada das mensagens\\m\u00eddias. Para resolver isto, o repo https://github.com/aljazceru/mattermost-retention criou um script de limpeza dos anexos e mensagens antigas. Basicamente voc\u00ea configura os dados do banco e a pasta 'data' do MM, tudo anterior ao per\u00edodo de reten\u00e7\u00e3o definido ser\u00e1 apagado. O processo demora um pouco mas resolve bem o problema de ac\u00famulo de mensagens e anexos. Recentemente eu fiz uma PR adicionando suporte ao Mysql, pois a vers\u00e3o da epoca s\u00f3 aceitava Postgres.","title":"Script de limpeza"},{"location":"aplicacoes/gluu/gluu/","text":"Gluu https://github.com/Jarzamendia/gluu Subindo vers\u00e3o b\u00e1sica com Docker-Compose ./pygluu-kubernetes.pyz helm-install Manual minikube start minikube addons enable ingress kubectl config use-context minikube ./pygluu-kubernetes-linux-amd64.pyz generate-settings ../pygluu-kubernetes-linux-amd64.pyz helm-install","title":"Gluu"},{"location":"aplicacoes/gluu/gluu/#gluu","text":"https://github.com/Jarzamendia/gluu","title":"Gluu"},{"location":"aplicacoes/gluu/gluu/#subindo-versao-basica-com-docker-compose","text":"./pygluu-kubernetes.pyz helm-install","title":"Subindo vers\u00e3o b\u00e1sica com Docker-Compose"},{"location":"aplicacoes/gluu/gluu/#manual","text":"minikube start minikube addons enable ingress kubectl config use-context minikube ./pygluu-kubernetes-linux-amd64.pyz generate-settings ../pygluu-kubernetes-linux-amd64.pyz helm-install","title":"Manual"},{"location":"mestrado/kubernetes/kubernetes/","text":"Mestrado em Kubernetes Informa\u00e7\u00f5es b\u00e1sicas Containers e Virtualiza\u00e7\u00e3o System Performance Evaluation of Para Virtualization, Container Virtualization, and Full Virtualization Using Xen, OpenVZ, and XenServer URL: https://ieeexplore.ieee.org/abstract/document/6906035 Introdu\u00e7\u00e3o O artigo trata sobre testes feitos em tr\u00eas formas de virtualiza\u00e7\u00e3o: Para Virtualiza\u00e7\u00e3o, Virtualiza\u00e7\u00e3o de Containers e Virtualiza\u00e7\u00e3o complete. Os autores discorrem sobre as diferen\u00e7as b\u00e1sicas de cada uma delas e por fim estipulam uma forma de teste de carga que ser\u00e1 feito para verificar qual dos tipos de virtualiza\u00e7\u00e3o entrega maior performance. Metodologia Os autores utilizaram a ferramenta unixBench em um SO Debian instalado em cada uma das plataformas de virtualiza\u00e7\u00e3o. A partir da execu\u00e7\u00e3o dos testes, eles geraram graficos para cada cenario e por fim geraram uma pontua\u00e7\u00e3o final para cada um dos tipos de virtualiza\u00e7\u00e3o. Conclus\u00e3o Ao final do processo, os autores concluem que a Virtualiza\u00e7\u00e3o Completa usando Xen Server \u00e9 a melhor, ja que apresentou a maior pontua\u00e7\u00e3o final e foi a mais performatica na maioria dos testes. Em alguns testes a virtualiza\u00e7\u00e3o por containers foi mais eficaz e em todos a para virtualiza\u00e7\u00e3o perdeu. Comentarios Ao observar os testes feitos pelos autores, pude observar que a virtualiza\u00e7\u00e3o completa ganha em cenarios onde o uso de recursos \u00e9 compartilhado entre processos. Isto me da a entender que nos casos de microservi\u00e7os ou containers simples, sem dependencias internas (apenas um processo), seria interessante usar Containers, em sistemas complexos, o melhor seria usar Virtualiza\u00e7\u00e3o Completa. Virtualization vs Containerization to Support PaaS URL: https://ieeexplore.ieee.org/abstract/document/6903537 Introdu\u00e7\u00e3o Os autores discorrem sobre as vantegens do uso de containes em PaaS. Eles discorrem sobre sabores de containers disponiveis no mercado, como LXC, Docker, Warden, lmcty e OpenVz. Metodologia Os autores fazem uma analise de cada um dos sabores informados, sem realmente tomar partido em qual seria melhor. Conclus\u00e3o Os autores encerram informando que as proximas PaaS devem usar containers para conseguir atender as demandas de velocidade que desenvolvedores precisam para hospedar suas aplica\u00e7\u00f5es. Comentarios Observando os tipos de containers informados pelos autores, podemos observar que o lmcty da Google se uniu ao Docker no projeto Libcontainer. O OpenVZ est\u00e1 se fundindo com o LCX; com isso realmente as op\u00e7\u00f5es se tornam: LXC solo, Libcontainer (Docker, RUNC, Containerd) ou Warden. Exploring Container Virtualization in IoT Clouds URL: https://ieeexplore.ieee.org/abstract/document/7501691 Introdu\u00e7\u00e3o Metodologia Conclus\u00e3o Comentarios System Performance Evaluation of Para Virtualization, Container Virtualization, and Full Virtualization Using Xen, OpenVZ, and XenServer https://ieeexplore.ieee.org/abstract/document/7431468 Economically Efficient Virtualization over Cloud Using Docker Containers https://ieeexplore.ieee.org/abstract/document/7819678 Hypervisor- vs. Container-based Virtualization https://www.net.in.tum.de/fileadmin/TUM/NET/NET-2016-07-1/NET-2016-07-1_01.pdf Cria\u00e7\u00e3o do Kubernetes Orquestra\u00e7\u00e3o de Containers Kubernetes na Nuvem Acesso ao cluster RBAC Tipos de Workload Networking Integra\u00e7\u00e3o com a Nubem Storage","title":"Kubernetes"},{"location":"mestrado/kubernetes/kubernetes/#mestrado-em-kubernetes","text":"","title":"Mestrado em Kubernetes"},{"location":"mestrado/kubernetes/kubernetes/#informacoes-basicas","text":"","title":"Informa\u00e7\u00f5es b\u00e1sicas"},{"location":"mestrado/kubernetes/kubernetes/#containers-e-virtualizacao","text":"","title":"Containers e Virtualiza\u00e7\u00e3o"},{"location":"mestrado/kubernetes/kubernetes/#system-performance-evaluation-of-para-virtualization-container-virtualization-and-full-virtualization-using-xen-openvz-and-xenserver","text":"URL: https://ieeexplore.ieee.org/abstract/document/6906035","title":"System Performance Evaluation of Para Virtualization, Container Virtualization, and Full Virtualization Using Xen, OpenVZ, and XenServer"},{"location":"mestrado/kubernetes/kubernetes/#introducao","text":"O artigo trata sobre testes feitos em tr\u00eas formas de virtualiza\u00e7\u00e3o: Para Virtualiza\u00e7\u00e3o, Virtualiza\u00e7\u00e3o de Containers e Virtualiza\u00e7\u00e3o complete. Os autores discorrem sobre as diferen\u00e7as b\u00e1sicas de cada uma delas e por fim estipulam uma forma de teste de carga que ser\u00e1 feito para verificar qual dos tipos de virtualiza\u00e7\u00e3o entrega maior performance.","title":"Introdu\u00e7\u00e3o"},{"location":"mestrado/kubernetes/kubernetes/#metodologia","text":"Os autores utilizaram a ferramenta unixBench em um SO Debian instalado em cada uma das plataformas de virtualiza\u00e7\u00e3o. A partir da execu\u00e7\u00e3o dos testes, eles geraram graficos para cada cenario e por fim geraram uma pontua\u00e7\u00e3o final para cada um dos tipos de virtualiza\u00e7\u00e3o.","title":"Metodologia"},{"location":"mestrado/kubernetes/kubernetes/#conclusao","text":"Ao final do processo, os autores concluem que a Virtualiza\u00e7\u00e3o Completa usando Xen Server \u00e9 a melhor, ja que apresentou a maior pontua\u00e7\u00e3o final e foi a mais performatica na maioria dos testes. Em alguns testes a virtualiza\u00e7\u00e3o por containers foi mais eficaz e em todos a para virtualiza\u00e7\u00e3o perdeu.","title":"Conclus\u00e3o"},{"location":"mestrado/kubernetes/kubernetes/#comentarios","text":"Ao observar os testes feitos pelos autores, pude observar que a virtualiza\u00e7\u00e3o completa ganha em cenarios onde o uso de recursos \u00e9 compartilhado entre processos. Isto me da a entender que nos casos de microservi\u00e7os ou containers simples, sem dependencias internas (apenas um processo), seria interessante usar Containers, em sistemas complexos, o melhor seria usar Virtualiza\u00e7\u00e3o Completa.","title":"Comentarios"},{"location":"mestrado/kubernetes/kubernetes/#virtualization-vs-containerization-to-support-paas","text":"URL: https://ieeexplore.ieee.org/abstract/document/6903537","title":"Virtualization vs Containerization to Support PaaS"},{"location":"mestrado/kubernetes/kubernetes/#introducao_1","text":"Os autores discorrem sobre as vantegens do uso de containes em PaaS. Eles discorrem sobre sabores de containers disponiveis no mercado, como LXC, Docker, Warden, lmcty e OpenVz.","title":"Introdu\u00e7\u00e3o"},{"location":"mestrado/kubernetes/kubernetes/#metodologia_1","text":"Os autores fazem uma analise de cada um dos sabores informados, sem realmente tomar partido em qual seria melhor.","title":"Metodologia"},{"location":"mestrado/kubernetes/kubernetes/#conclusao_1","text":"Os autores encerram informando que as proximas PaaS devem usar containers para conseguir atender as demandas de velocidade que desenvolvedores precisam para hospedar suas aplica\u00e7\u00f5es.","title":"Conclus\u00e3o"},{"location":"mestrado/kubernetes/kubernetes/#comentarios_1","text":"Observando os tipos de containers informados pelos autores, podemos observar que o lmcty da Google se uniu ao Docker no projeto Libcontainer. O OpenVZ est\u00e1 se fundindo com o LCX; com isso realmente as op\u00e7\u00f5es se tornam: LXC solo, Libcontainer (Docker, RUNC, Containerd) ou Warden.","title":"Comentarios"},{"location":"mestrado/kubernetes/kubernetes/#exploring-container-virtualization-in-iot-clouds","text":"URL: https://ieeexplore.ieee.org/abstract/document/7501691","title":"Exploring Container Virtualization in IoT Clouds"},{"location":"mestrado/kubernetes/kubernetes/#introducao_2","text":"","title":"Introdu\u00e7\u00e3o"},{"location":"mestrado/kubernetes/kubernetes/#metodologia_2","text":"","title":"Metodologia"},{"location":"mestrado/kubernetes/kubernetes/#conclusao_2","text":"","title":"Conclus\u00e3o"},{"location":"mestrado/kubernetes/kubernetes/#comentarios_2","text":"System Performance Evaluation of Para Virtualization, Container Virtualization, and Full Virtualization Using Xen, OpenVZ, and XenServer https://ieeexplore.ieee.org/abstract/document/7431468 Economically Efficient Virtualization over Cloud Using Docker Containers https://ieeexplore.ieee.org/abstract/document/7819678 Hypervisor- vs. Container-based Virtualization https://www.net.in.tum.de/fileadmin/TUM/NET/NET-2016-07-1/NET-2016-07-1_01.pdf","title":"Comentarios"},{"location":"mestrado/kubernetes/kubernetes/#criacao-do-kubernetes","text":"","title":"Cria\u00e7\u00e3o do Kubernetes"},{"location":"mestrado/kubernetes/kubernetes/#orquestracao-de-containers","text":"","title":"Orquestra\u00e7\u00e3o de Containers"},{"location":"mestrado/kubernetes/kubernetes/#kubernetes-na-nuvem","text":"","title":"Kubernetes na Nuvem"},{"location":"mestrado/kubernetes/kubernetes/#acesso-ao-cluster","text":"","title":"Acesso ao cluster"},{"location":"mestrado/kubernetes/kubernetes/#rbac","text":"","title":"RBAC"},{"location":"mestrado/kubernetes/kubernetes/#tipos-de-workload","text":"","title":"Tipos de Workload"},{"location":"mestrado/kubernetes/kubernetes/#networking","text":"","title":"Networking"},{"location":"mestrado/kubernetes/kubernetes/#integracao-com-a-nubem","text":"","title":"Integra\u00e7\u00e3o com a Nubem"},{"location":"mestrado/kubernetes/kubernetes/#storage","text":"","title":"Storage"},{"location":"mestrado/kubernetes/tese/","text":"Tese Kubernetes: Cria\u00e7\u00e3o de plataformas de hospedagem de aplica\u00e7\u00f5es para o servi\u00e7o p\u00fablico Kubernetes: Cria\u00e7\u00e3o de plataformas de hospedagem de cargas de trabalho para o servi\u00e7o p\u00fablico Orquestra\u00e7\u00e3o de cargas de trabalho usando containers no servi\u00e7o p\u00fablico Nuvens privadas para o servi\u00e7o p\u00fablico: Uma aproxima\u00e7\u00e3o com Kubernetes Containers Esta tese deve agregar um bom conhecimento teorico sobre containers, sua diferen\u00e7a referente a outros metodos de virtualiza\u00e7\u00e3o e principalmente deve responder o que \u00e9 um container de acordo com a literatura. Pergunta: O que \u00e9 um container? Pergunta: Como um container funciona? Pergunta: Como podemos tomar vantagens pelo uso de containers. Workload Workload, ou carga de trabalho pode ser um ponto importante na tese, ja que no final das contas, o objetivo de uma nuvem privada \u00e9 fazer com que cargas de trabalho de variado tipo seja levado a cabo da melhor maneira possivel.","title":"Tese"},{"location":"mestrado/kubernetes/tese/#tese","text":"Kubernetes: Cria\u00e7\u00e3o de plataformas de hospedagem de aplica\u00e7\u00f5es para o servi\u00e7o p\u00fablico Kubernetes: Cria\u00e7\u00e3o de plataformas de hospedagem de cargas de trabalho para o servi\u00e7o p\u00fablico Orquestra\u00e7\u00e3o de cargas de trabalho usando containers no servi\u00e7o p\u00fablico Nuvens privadas para o servi\u00e7o p\u00fablico: Uma aproxima\u00e7\u00e3o com Kubernetes","title":"Tese"},{"location":"mestrado/kubernetes/tese/#containers","text":"Esta tese deve agregar um bom conhecimento teorico sobre containers, sua diferen\u00e7a referente a outros metodos de virtualiza\u00e7\u00e3o e principalmente deve responder o que \u00e9 um container de acordo com a literatura. Pergunta: O que \u00e9 um container? Pergunta: Como um container funciona? Pergunta: Como podemos tomar vantagens pelo uso de containers.","title":"Containers"},{"location":"mestrado/kubernetes/tese/#workload","text":"Workload, ou carga de trabalho pode ser um ponto importante na tese, ja que no final das contas, o objetivo de uma nuvem privada \u00e9 fazer com que cargas de trabalho de variado tipo seja levado a cabo da melhor maneira possivel.","title":"Workload"},{"location":"monitoramento/prometheus/prometheus/","text":"Monitoramento de Kubernetes usando Prometheus O Kubernetes tornou extremamente f\u00e1cil executar grandes cargas de trabalho em ambientes clusterizados de alta disponibilidade. Com isso, tornou-se poss\u00edvel hospedar de maneira relativamente f\u00e1cil centenas de aplica\u00e7\u00f5es em clusters de dezenas de servidores. Ao mesmo tempo em que aumentamos o n\u00famero de aplica\u00e7\u00f5es e servidores em nosso ambiente, tamb\u00e9m aumentamos a complexidade do gerenciamento de nossos ativos. Para ajudar no monitoramento de tanto nossas cargas de trabalho, quanto do pr\u00f3prio ambiente em si, diversas aplica\u00e7\u00f5es foram criadas. Algumas delas, como o Dynatrace ou o Datalog s\u00e3o pagas, cobrando pela hospedagem de nossos dados e pelo suporte empresarial oferecido. Outras, como o Prometheus ou o Elasticsearch s\u00e3o de c\u00f3digo aberto, totalmente gratuitas. Mesmo nessas aplica\u00e7\u00f5es, tamb\u00e9m \u00e9 poss\u00edvel adquirir o suporte empresarial de seus criadores ou usar seus ambientes gerenciados e pagar pelos seus servi\u00e7os. Por outro lado, tamb\u00e9m \u00e9 poss\u00edvel assumir totalmente a gest\u00e3o e hospedagem dos dados monitorados em nosso ambiente. Para isto podemos usar as op\u00e7\u00f5es de c\u00f3digo aberto e com isso mitigar os valores pagos a terceiros. O que \u00e9 o Prometheus Uma das plataformas mais usadas pela comunidade \u00e9 o Prometheus, neste documento iremos tratar de sua instala\u00e7\u00e3o em um ambiente de testes do Kubernetes usando o Minikube. O Prometheus \u00e9 uma plataforma de monitoramento extremamente completa e customiz\u00e1vel, por muitos \u00e9 considerado o sistema de monitoramento padr\u00e3o da nuvem. Para ser mais exato, o Prometheus \u00e9 uma plataforma de c\u00f3digo aberto que coleta m\u00e9tricas e as guarda em forma de dados de s\u00e9rie temporal. Estes dados podem ent\u00e3o ser pesquisados e organizados, de forma a criar gr\u00e1ficos e dashboards conforme nossas necessidades. As aplica\u00e7\u00f5es e ambientes devem expor esses dados em endpoints HTTP que ser\u00e3o acessados pelo Prometheus. Quando tratamos de projetos open source, o Prometheus brilha. O protocolo OpenMetrics , criado como uma forma de padronizar o formato de exporta\u00e7\u00e3o de m\u00e9tricas para o Prometheus \u00e9 muito difundido na comunidade. Mesmo em aplica\u00e7\u00f5es que a princ\u00edpio n\u00e3o tem suporte a exportar m\u00e9tricas no formato do Prometheus, facilmente conseguimos encontrar extens\u00f5es da comunidade que podem ser inclu\u00eddas na aplica\u00e7\u00e3o, adicionando ent\u00e3o esta funcionalidade. Junto a isto, criar e editar gr\u00e1ficos e dashboards no Grafana (O visualizador de m\u00e9tricas natural do Prometheus) \u00e9 extremamente f\u00e1cil e intuitivo. Al\u00e9m disso, existem provavelmente milhares de dashboards compartilhados na internet para todo tipo de aplica\u00e7\u00e3o j\u00e1 prontos para usarmos em nosso ambiente. Prometheus no Minikube Dada esta introdu\u00e7\u00e3o, vamos demonstrar a instala\u00e7\u00e3o de um ambiente de monitoramento de um Kubernetes, neste caso n\u00e3o trataremos de um cluster, pois usaremos um Minikube com apenas um n\u00f3. Caso voc\u00ea queira testar tamb\u00e9m, os seguintes requisitos s\u00e3o necess\u00e1rios: Minikube Helm kubectl N\u00e3o abordarei a instala\u00e7\u00e3o deles neste documento, ent\u00e3o antes de seguir os pr\u00f3ximos pontos, prepare-os de forma adequada em sua esta\u00e7\u00e3o de trabalho. Caso voc\u00ea instale o Kubernetes em um servidor diferente remoto, \u00e9 importante que voc\u00ea execute os comandos de \"port-forward\" direto de sua esta\u00e7\u00e3o. Caso isto n\u00e3o seja poss\u00edvel, voc\u00ea ter\u00e1 que customizar estes comandos para conseguir acessar os recursos de seu cluster ou prover outros m\u00e9todos de acesso. Iniciando o Minikube O Minikube usar\u00e1 o Docker de minha esta\u00e7\u00e3o para criar um ambiente de testes do K8S com um node. Em alguns casos ele pode usar VM's em um hypervisor. De qualquer modo, ele ir\u00e1 tratar de preparar a integra\u00e7\u00e3o entre nosso kubectl local e o cluster K8S. Ent\u00e3o vamos l\u00e1, para iniciar o ambiente execute: minikube start Com nosso ambiente iniciado, podemos verificar se tudo est\u00e1 OK rodando alguns comandos: kubectl get nodes Que nos retornar\u00e1 uma lista com os nodes de nosso cluster. kubectl get pods -A Que nos retornar\u00e1 os pods de todos os Namespaces. Algo parecido com isso ser\u00e1 retornado... Prometheus Chart Para simplificar a instala\u00e7\u00e3o de ambientes de monitoramento de clusters Kubernetes usando Prometheus, um Chart foi criado. Com ele, iremos implementar toda a infraestrutura necess\u00e1ria para uma instala\u00e7\u00e3o padr\u00e3o do Prometheus, Grafana, Node Exporter, Metric Server e Alert Manager. O ambiente ainda n\u00e3o estar\u00e1 pronto para produ\u00e7\u00e3o, por\u00e9m ser\u00e1 poss\u00edvel testar praticamente todas as caracter\u00edsticas do ambiente. Come\u00e7aremos criando um namespace para abrigar todos os objetos criados pelo Operator: kubectl create namespace prometheus Ap\u00f3s isso, adicionaremos o reposit\u00f3rio do chart em nosso ambiente e o instalaremos no namespace que criamos. helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm install prometheus prometheus-community/kube-prometheus-stack --namespace prometheus Algo assim deve ser retornado, eu removi os Warnings de API\u2019s descontinuadas para facilitar! O processo de instala\u00e7\u00e3o demora alguns minutos. Podemos usar um comando para verificar a instala\u00e7\u00e3o. Ao final o ambiente deve ficar da seguinte forma: kubectl get pods -n prometheus De maneira simplificada, cada um desses pods tem a seguinte finalidade: Alertmanager: Gerenciador de alertas do ambiente. Grafana: Frontend onde veremos os gr\u00e1ficos. Prometheus-Operator: Gerenciador da instala\u00e7\u00e3o. Kube-State-Metrics: Exp\u00f5e as m\u00e9tricas dos recursos internos do Kubernetes Prometheus: Quem ir\u00e1 capturar e guardar as m\u00e9tricas. Node-Exporter: Exp\u00f5e as m\u00e9tricas dos servidores. Instala\u00e7\u00e3o pronta, e agora? Com a finaliza\u00e7\u00e3o da instala\u00e7\u00e3o do Prometheus (e outros recursos) em nosso cluster, podemos acess\u00e1-lo com os seguintes comandos: kubectl port-forward -n prometheus service/prometheus-operated 9090:9090 Ap\u00f3s isto, podemos acessar no navegador de nossa esta\u00e7\u00e3o de trabalho em: http://localhost:9090 e verificar a interface web do Prometheus! Certo, tudo certo com o Prometheus, agora vamos acessar o Grafana. Com o seguinte comando podemos acess\u00e1-lo: kubectl port-forward -n prometheus service/prometheus-grafana 3000:80 Agora podemos acessar http://localhost:3000 para ter acesso ao Grafana! As credenciais de acesso s\u00e3o: admin/prom-operator. Caso o projeto evolua (o que \u00e9 bem poss\u00edvel) e elas sejam alteradas, \u00e9 poss\u00edvel recuper\u00e1-las atrav\u00e9s da secret criada no ambiente: kubectl get secret -n prometheus prometheus-grafana -o yaml A secret guarda o usu\u00e1rio e a senha em base64, basta decodificar os valores para ter acesso a senha do ambiente. Dashboards O ambiente j\u00e1 vem com v\u00e1rios dashboards prontos. Eles podem ser acessados aqui . N\u00e3o trataremos disso nesse documento, mas \u00e9 f\u00e1cil exportar partes interessantes de um dashboard e agreg\u00e1-los todos em um \u00fanico dashboard de gerenciamento. O Grafana tamb\u00e9m tem fun\u00e7\u00f5es de criar playlists de Dashboards para deixarmos rodando em um monitor separado. O Grafana \u00e9 uma aplica\u00e7\u00e3o bem completa. Podemos configur\u00e1-lo para usar autentica\u00e7\u00e3o via LDAP, configurar alertas via Slack ou Mattermost e adicionar outras fontes de dados. Al\u00e9m disso, existem v\u00e1rios plugins para customizar ainda mais o ambiente. Nesta p\u00e1gina podemos encontrar dashboards oficiais e da comunidade para download. Sobre clusters Estes procedimentos podem ser utilizados em ambientes com mais de um node com poucas modifica\u00e7\u00f5es. O Node-Exporter \u00e9 implementado de forma a ter um pod iniciado em cada servidor do cluster, sendo assim, as m\u00e9tricas de todos os servidores ser\u00e3o coletadas. Os dados ser\u00e3o persistidos por 10 dias, por\u00e9m da forma atual, caso o pod do Prometheus reinicie, todas as m\u00e9tricas ser\u00e3o perdidas. Isso pode ser resolvido de algumas formas, por\u00e9m n\u00e3o trataremos disso nesse documento. Provavelmente, caso voc\u00ea tente executar os comandos deste documento em um cluster j\u00e1 em funcionamento voc\u00ea ter\u00e1 resultados muito parecidos com os executados em um ambiente de teste com Minikube, esta \u00e9 a beleza dos Helm Charts e Operators do Kubernetes. Palavras finais Por mais que este ambiente a princ\u00edpio pare\u00e7a completo, ainda faltam algumas coisas para realmente o colocarmos em produ\u00e7\u00e3o. Ser\u00e1 necess\u00e1rio prover o acesso a pessoas fora do cluster pelo menos ao Grafana. Temos que emitir certificados digitais para as URLs externas e gerenciar a persist\u00eancia de dados do Prometheus, afinal n\u00e3o queremos perder nossas m\u00e9tricas. Al\u00e9m disto, o ambiente est\u00e1 com suas defini\u00e7\u00f5es padr\u00f5es, ent\u00e3o teremos que observar nossas necessidades para alterar coisas como tempo de reten\u00e7\u00e3o, formas de autentica\u00e7\u00e3o e canais de alertas. Isso tudo pode ser feito no decorrer do tempo, conforme aprendemos melhor como usar este ambiente. Essas customiza\u00e7\u00f5es podem ser feitas durante a instala\u00e7\u00e3o do ambiente usando o Chart do Helm. Em geral usa-se um arquivo chamado \"values.yaml\" em conjunto com o comando de instala\u00e7\u00e3o: helm install prometheus prometheus-community/kube-prometheus-stack -f values.yaml --namespace prometheus Este arquivo pode ser encontrado aqui com seus valores padr\u00f5es. Por fim, Remo\u00e7\u00e3o do ambiente Caso voc\u00ea queira remover a instala\u00e7\u00e3o, isso pode ser feito com o comando: helm uninstall prometheus -n prometheus Por algum motivo, o helm n\u00e3o remove alguns Custom Resources criados durante a instala\u00e7\u00e3o. Verifique isso caso delete o ambiente! E o cluster de Kubernetes gerido pelo Minikube pode ser deletado com: minikube delete Ent\u00e3o \u00e9 isso, assim encerro este documento, onde tratamos de alguns aspectos do Prometheus no Kubernetes. Entrem em contato caso encontrem algum erro neste documento ou queiram mostrar algo interessante sobre esse ambiente!","title":"Prometheus"},{"location":"monitoramento/prometheus/prometheus/#monitoramento-de-kubernetes-usando-prometheus","text":"O Kubernetes tornou extremamente f\u00e1cil executar grandes cargas de trabalho em ambientes clusterizados de alta disponibilidade. Com isso, tornou-se poss\u00edvel hospedar de maneira relativamente f\u00e1cil centenas de aplica\u00e7\u00f5es em clusters de dezenas de servidores. Ao mesmo tempo em que aumentamos o n\u00famero de aplica\u00e7\u00f5es e servidores em nosso ambiente, tamb\u00e9m aumentamos a complexidade do gerenciamento de nossos ativos. Para ajudar no monitoramento de tanto nossas cargas de trabalho, quanto do pr\u00f3prio ambiente em si, diversas aplica\u00e7\u00f5es foram criadas. Algumas delas, como o Dynatrace ou o Datalog s\u00e3o pagas, cobrando pela hospedagem de nossos dados e pelo suporte empresarial oferecido. Outras, como o Prometheus ou o Elasticsearch s\u00e3o de c\u00f3digo aberto, totalmente gratuitas. Mesmo nessas aplica\u00e7\u00f5es, tamb\u00e9m \u00e9 poss\u00edvel adquirir o suporte empresarial de seus criadores ou usar seus ambientes gerenciados e pagar pelos seus servi\u00e7os. Por outro lado, tamb\u00e9m \u00e9 poss\u00edvel assumir totalmente a gest\u00e3o e hospedagem dos dados monitorados em nosso ambiente. Para isto podemos usar as op\u00e7\u00f5es de c\u00f3digo aberto e com isso mitigar os valores pagos a terceiros.","title":"Monitoramento de Kubernetes usando Prometheus"},{"location":"monitoramento/prometheus/prometheus/#o-que-e-o-prometheus","text":"Uma das plataformas mais usadas pela comunidade \u00e9 o Prometheus, neste documento iremos tratar de sua instala\u00e7\u00e3o em um ambiente de testes do Kubernetes usando o Minikube. O Prometheus \u00e9 uma plataforma de monitoramento extremamente completa e customiz\u00e1vel, por muitos \u00e9 considerado o sistema de monitoramento padr\u00e3o da nuvem. Para ser mais exato, o Prometheus \u00e9 uma plataforma de c\u00f3digo aberto que coleta m\u00e9tricas e as guarda em forma de dados de s\u00e9rie temporal. Estes dados podem ent\u00e3o ser pesquisados e organizados, de forma a criar gr\u00e1ficos e dashboards conforme nossas necessidades. As aplica\u00e7\u00f5es e ambientes devem expor esses dados em endpoints HTTP que ser\u00e3o acessados pelo Prometheus. Quando tratamos de projetos open source, o Prometheus brilha. O protocolo OpenMetrics , criado como uma forma de padronizar o formato de exporta\u00e7\u00e3o de m\u00e9tricas para o Prometheus \u00e9 muito difundido na comunidade. Mesmo em aplica\u00e7\u00f5es que a princ\u00edpio n\u00e3o tem suporte a exportar m\u00e9tricas no formato do Prometheus, facilmente conseguimos encontrar extens\u00f5es da comunidade que podem ser inclu\u00eddas na aplica\u00e7\u00e3o, adicionando ent\u00e3o esta funcionalidade. Junto a isto, criar e editar gr\u00e1ficos e dashboards no Grafana (O visualizador de m\u00e9tricas natural do Prometheus) \u00e9 extremamente f\u00e1cil e intuitivo. Al\u00e9m disso, existem provavelmente milhares de dashboards compartilhados na internet para todo tipo de aplica\u00e7\u00e3o j\u00e1 prontos para usarmos em nosso ambiente.","title":"O que \u00e9 o Prometheus"},{"location":"monitoramento/prometheus/prometheus/#prometheus-no-minikube","text":"Dada esta introdu\u00e7\u00e3o, vamos demonstrar a instala\u00e7\u00e3o de um ambiente de monitoramento de um Kubernetes, neste caso n\u00e3o trataremos de um cluster, pois usaremos um Minikube com apenas um n\u00f3. Caso voc\u00ea queira testar tamb\u00e9m, os seguintes requisitos s\u00e3o necess\u00e1rios: Minikube Helm kubectl N\u00e3o abordarei a instala\u00e7\u00e3o deles neste documento, ent\u00e3o antes de seguir os pr\u00f3ximos pontos, prepare-os de forma adequada em sua esta\u00e7\u00e3o de trabalho. Caso voc\u00ea instale o Kubernetes em um servidor diferente remoto, \u00e9 importante que voc\u00ea execute os comandos de \"port-forward\" direto de sua esta\u00e7\u00e3o. Caso isto n\u00e3o seja poss\u00edvel, voc\u00ea ter\u00e1 que customizar estes comandos para conseguir acessar os recursos de seu cluster ou prover outros m\u00e9todos de acesso.","title":"Prometheus no Minikube"},{"location":"monitoramento/prometheus/prometheus/#iniciando-o-minikube","text":"O Minikube usar\u00e1 o Docker de minha esta\u00e7\u00e3o para criar um ambiente de testes do K8S com um node. Em alguns casos ele pode usar VM's em um hypervisor. De qualquer modo, ele ir\u00e1 tratar de preparar a integra\u00e7\u00e3o entre nosso kubectl local e o cluster K8S. Ent\u00e3o vamos l\u00e1, para iniciar o ambiente execute: minikube start Com nosso ambiente iniciado, podemos verificar se tudo est\u00e1 OK rodando alguns comandos: kubectl get nodes Que nos retornar\u00e1 uma lista com os nodes de nosso cluster. kubectl get pods -A Que nos retornar\u00e1 os pods de todos os Namespaces. Algo parecido com isso ser\u00e1 retornado...","title":"Iniciando o Minikube"},{"location":"monitoramento/prometheus/prometheus/#prometheus-chart","text":"Para simplificar a instala\u00e7\u00e3o de ambientes de monitoramento de clusters Kubernetes usando Prometheus, um Chart foi criado. Com ele, iremos implementar toda a infraestrutura necess\u00e1ria para uma instala\u00e7\u00e3o padr\u00e3o do Prometheus, Grafana, Node Exporter, Metric Server e Alert Manager. O ambiente ainda n\u00e3o estar\u00e1 pronto para produ\u00e7\u00e3o, por\u00e9m ser\u00e1 poss\u00edvel testar praticamente todas as caracter\u00edsticas do ambiente. Come\u00e7aremos criando um namespace para abrigar todos os objetos criados pelo Operator: kubectl create namespace prometheus Ap\u00f3s isso, adicionaremos o reposit\u00f3rio do chart em nosso ambiente e o instalaremos no namespace que criamos. helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm install prometheus prometheus-community/kube-prometheus-stack --namespace prometheus Algo assim deve ser retornado, eu removi os Warnings de API\u2019s descontinuadas para facilitar! O processo de instala\u00e7\u00e3o demora alguns minutos. Podemos usar um comando para verificar a instala\u00e7\u00e3o. Ao final o ambiente deve ficar da seguinte forma: kubectl get pods -n prometheus De maneira simplificada, cada um desses pods tem a seguinte finalidade: Alertmanager: Gerenciador de alertas do ambiente. Grafana: Frontend onde veremos os gr\u00e1ficos. Prometheus-Operator: Gerenciador da instala\u00e7\u00e3o. Kube-State-Metrics: Exp\u00f5e as m\u00e9tricas dos recursos internos do Kubernetes Prometheus: Quem ir\u00e1 capturar e guardar as m\u00e9tricas. Node-Exporter: Exp\u00f5e as m\u00e9tricas dos servidores.","title":"Prometheus Chart"},{"location":"monitoramento/prometheus/prometheus/#instalacao-pronta-e-agora","text":"Com a finaliza\u00e7\u00e3o da instala\u00e7\u00e3o do Prometheus (e outros recursos) em nosso cluster, podemos acess\u00e1-lo com os seguintes comandos: kubectl port-forward -n prometheus service/prometheus-operated 9090:9090 Ap\u00f3s isto, podemos acessar no navegador de nossa esta\u00e7\u00e3o de trabalho em: http://localhost:9090 e verificar a interface web do Prometheus! Certo, tudo certo com o Prometheus, agora vamos acessar o Grafana. Com o seguinte comando podemos acess\u00e1-lo: kubectl port-forward -n prometheus service/prometheus-grafana 3000:80 Agora podemos acessar http://localhost:3000 para ter acesso ao Grafana! As credenciais de acesso s\u00e3o: admin/prom-operator. Caso o projeto evolua (o que \u00e9 bem poss\u00edvel) e elas sejam alteradas, \u00e9 poss\u00edvel recuper\u00e1-las atrav\u00e9s da secret criada no ambiente: kubectl get secret -n prometheus prometheus-grafana -o yaml A secret guarda o usu\u00e1rio e a senha em base64, basta decodificar os valores para ter acesso a senha do ambiente.","title":"Instala\u00e7\u00e3o pronta, e agora?"},{"location":"monitoramento/prometheus/prometheus/#dashboards","text":"O ambiente j\u00e1 vem com v\u00e1rios dashboards prontos. Eles podem ser acessados aqui . N\u00e3o trataremos disso nesse documento, mas \u00e9 f\u00e1cil exportar partes interessantes de um dashboard e agreg\u00e1-los todos em um \u00fanico dashboard de gerenciamento. O Grafana tamb\u00e9m tem fun\u00e7\u00f5es de criar playlists de Dashboards para deixarmos rodando em um monitor separado. O Grafana \u00e9 uma aplica\u00e7\u00e3o bem completa. Podemos configur\u00e1-lo para usar autentica\u00e7\u00e3o via LDAP, configurar alertas via Slack ou Mattermost e adicionar outras fontes de dados. Al\u00e9m disso, existem v\u00e1rios plugins para customizar ainda mais o ambiente. Nesta p\u00e1gina podemos encontrar dashboards oficiais e da comunidade para download.","title":"Dashboards"},{"location":"monitoramento/prometheus/prometheus/#sobre-clusters","text":"Estes procedimentos podem ser utilizados em ambientes com mais de um node com poucas modifica\u00e7\u00f5es. O Node-Exporter \u00e9 implementado de forma a ter um pod iniciado em cada servidor do cluster, sendo assim, as m\u00e9tricas de todos os servidores ser\u00e3o coletadas. Os dados ser\u00e3o persistidos por 10 dias, por\u00e9m da forma atual, caso o pod do Prometheus reinicie, todas as m\u00e9tricas ser\u00e3o perdidas. Isso pode ser resolvido de algumas formas, por\u00e9m n\u00e3o trataremos disso nesse documento. Provavelmente, caso voc\u00ea tente executar os comandos deste documento em um cluster j\u00e1 em funcionamento voc\u00ea ter\u00e1 resultados muito parecidos com os executados em um ambiente de teste com Minikube, esta \u00e9 a beleza dos Helm Charts e Operators do Kubernetes.","title":"Sobre clusters"},{"location":"monitoramento/prometheus/prometheus/#palavras-finais","text":"Por mais que este ambiente a princ\u00edpio pare\u00e7a completo, ainda faltam algumas coisas para realmente o colocarmos em produ\u00e7\u00e3o. Ser\u00e1 necess\u00e1rio prover o acesso a pessoas fora do cluster pelo menos ao Grafana. Temos que emitir certificados digitais para as URLs externas e gerenciar a persist\u00eancia de dados do Prometheus, afinal n\u00e3o queremos perder nossas m\u00e9tricas. Al\u00e9m disto, o ambiente est\u00e1 com suas defini\u00e7\u00f5es padr\u00f5es, ent\u00e3o teremos que observar nossas necessidades para alterar coisas como tempo de reten\u00e7\u00e3o, formas de autentica\u00e7\u00e3o e canais de alertas. Isso tudo pode ser feito no decorrer do tempo, conforme aprendemos melhor como usar este ambiente. Essas customiza\u00e7\u00f5es podem ser feitas durante a instala\u00e7\u00e3o do ambiente usando o Chart do Helm. Em geral usa-se um arquivo chamado \"values.yaml\" em conjunto com o comando de instala\u00e7\u00e3o: helm install prometheus prometheus-community/kube-prometheus-stack -f values.yaml --namespace prometheus Este arquivo pode ser encontrado aqui com seus valores padr\u00f5es. Por fim,","title":"Palavras finais"},{"location":"monitoramento/prometheus/prometheus/#remocao-do-ambiente","text":"Caso voc\u00ea queira remover a instala\u00e7\u00e3o, isso pode ser feito com o comando: helm uninstall prometheus -n prometheus Por algum motivo, o helm n\u00e3o remove alguns Custom Resources criados durante a instala\u00e7\u00e3o. Verifique isso caso delete o ambiente! E o cluster de Kubernetes gerido pelo Minikube pode ser deletado com: minikube delete Ent\u00e3o \u00e9 isso, assim encerro este documento, onde tratamos de alguns aspectos do Prometheus no Kubernetes. Entrem em contato caso encontrem algum erro neste documento ou queiram mostrar algo interessante sobre esse ambiente!","title":"Remo\u00e7\u00e3o do ambiente"}]}